{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Ludwig\n",
    "\n",
    "Ludwig is a toolbox built on top of TensorFlow that allows to train and test deep learning models without the need to write code.\n",
    "\n",
    "All you need to provide is a CSV file containing your data, a list of columns to use as inputs, and a list of columns to use as outputs, Ludwig will do the rest. Simple commands can be used to train models both locally and in a distributed way, and to use them to predict on new data.\n",
    "(note also HDF5 and json input is available)\n",
    "\n",
    "Developed by Uber, is release under the open source Apache License 2.0.\n",
    "\n",
    "Available @ https://github.com/uber/ludwig\n",
    "\n",
    "### installation and steps\n",
    "\n",
    "#### Install:   \n",
    "pip install ludwig  \n",
    "\n",
    "python -m spacy download en\n",
    "\n",
    "\n",
    "#### Train:    \n",
    "Prepare your data in a CSV file, define input and output feature in a model definition YAML file.\n",
    "\n",
    "#### Predict:    \n",
    "use a pre-trained model to predict the output targets.\n",
    "\n",
    "#### Visualize:    \n",
    "Ludwig comes with many visualization options to understand deep learning models performance and compare their predictions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset examined\n",
    "\n",
    "In our examples we will use a subset of patent data taken from EPO PATSTAT (patentdata.csv);\n",
    "\n",
    "the data contains 5.000 EP applications with the following fields\n",
    "\n",
    "APPLN_AUTH patent filing office (EPO)\n",
    "APPLN_ID  application unique id\n",
    "EARLIEST_FILING_YEAR   priority year\n",
    "APPLN_ABSTRACT   patent abstract\n",
    "IPC4  first IPC - leading 4 chars\n",
    "PSN_NAME   first applicant standardized name\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EARLIEST_FILING_YEAR</th>\n",
       "      <th>APPLN_ABSTRACT</th>\n",
       "      <th>PSN_NAME</th>\n",
       "      <th>IPC4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1999</td>\n",
       "      <td>A mobile station (MS) that comprises an interf...</td>\n",
       "      <td>NOKIA CORPORATION</td>\n",
       "      <td>G06K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1991</td>\n",
       "      <td>Methods are disclosed for the production of an...</td>\n",
       "      <td>MRC (MEDICAL RESEARCH COUNCIL)</td>\n",
       "      <td>G01N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1999</td>\n",
       "      <td>The detector includes scintillators (S1 to S5)...</td>\n",
       "      <td>PHILIPS INTELLECTUAL PROPERTY &amp; STANDARDS</td>\n",
       "      <td>G01T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1999</td>\n",
       "      <td>The specification describes techniques for wir...</td>\n",
       "      <td>LUCENT TECHNOLOGIES</td>\n",
       "      <td>H01L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1999</td>\n",
       "      <td>The specification describes source/drain conta...</td>\n",
       "      <td>LUCENT TECHNOLOGIES</td>\n",
       "      <td>H01L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EARLIEST_FILING_YEAR                                     APPLN_ABSTRACT  \\\n",
       "0                  1999  A mobile station (MS) that comprises an interf...   \n",
       "1                  1991  Methods are disclosed for the production of an...   \n",
       "2                  1999  The detector includes scintillators (S1 to S5)...   \n",
       "3                  1999  The specification describes techniques for wir...   \n",
       "4                  1999  The specification describes source/drain conta...   \n",
       "\n",
       "                                    PSN_NAME  IPC4  \n",
       "0                          NOKIA CORPORATION  G06K  \n",
       "1             MRC (MEDICAL RESEARCH COUNCIL)  G01N  \n",
       "2  PHILIPS INTELLECTUAL PROPERTY & STANDARDS  G01T  \n",
       "3                        LUCENT TECHNOLOGIES  H01L  \n",
       "4                        LUCENT TECHNOLOGIES  H01L  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data =pd.read_csv(\"patentdata.csv\")\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EARLIEST_FILING_YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2005.164800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.096217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1979.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2005.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2007.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2007.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2008.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       EARLIEST_FILING_YEAR\n",
       "count           5000.000000\n",
       "mean            2005.164800\n",
       "std                4.096217\n",
       "min             1979.000000\n",
       "25%             2005.000000\n",
       "50%             2007.000000\n",
       "75%             2007.000000\n",
       "max             2008.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data definition in Ludwig\n",
    "\n",
    "Previously was explain that training a model in Ludwig is pretty straightforward: you provide a CSV dataset and a model definition YAML file.\n",
    "\n",
    "The model definition contains a list of input features and output features, all you have to do is specify names of the columns in the CSV that are inputs to your model alongside with their datatypes, and names of columns in the CSV that will be outputs, the target variables which the model will learn to predict. Ludwig will compose a deep learning model accordingly and train it for you.\n",
    "\n",
    "Currently the available datatypes in Ludwig are:\n",
    "\n",
    "binary\n",
    "\n",
    "numerical\n",
    "\n",
    "category\n",
    "\n",
    "set\n",
    "\n",
    "bag\n",
    "\n",
    "sequence\n",
    "\n",
    "text\n",
    "\n",
    "timeseries\n",
    "\n",
    "image\n",
    "\n",
    "The model definition can contain additional information, in particular how to preprocess each column in the CSV.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "From Patents dataset we will use abstract, year and applicant standard name to forecast the content of IPC4 field\n",
    "\n",
    "EARLIEST_FILING_YEAR,APPLN_ABSTRACT,PSN_NAME,IPC4\n",
    "\n",
    "\"EP\",1,1999,\"a lot of text\",\"G06K\",\"NOKIA CORPORATION\"\n",
    "\n",
    "Model training by calling \n",
    "\n",
    "ludwig train [options]\n",
    "\n",
    "  --data_csv DATA_CSV   input data CSV file. If it has a split column, it will\n",
    "                        be used for splitting (0: train, 1: validation, 2:\n",
    "                        test), otherwise the dataset will be randomly split\n",
    "                        \n",
    "  -mdf --model_definition_file MODEL_DEFINITION_FILE\n",
    "                        YAML file describing the model. \n",
    "                        \n",
    "  --output_directory OUTPUT_DIRECTORY\n",
    "                        directory that contains the results                        \n",
    "                        \n",
    "\n",
    "(refer to: https://uber.github.io/ludwig/user_guide/)\n",
    "\n",
    "We will use a multi input model defined in modeldefinition.yaml file\n",
    "\n",
    "\n",
    "The structure of the model definition file is a dictionary with five keys:\n",
    "\n",
    "\n",
    "input_features: []\n",
    "\n",
    "combiner: {}\n",
    "\n",
    "output_features: []\n",
    "\n",
    "training: {}\n",
    "\n",
    "preprocessing: {}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "input_features:\n",
    "\n",
    "    -\n",
    "    \n",
    "        name: EARLIEST_FILING_YEAR\n",
    "        \n",
    "        type: numerical\n",
    "        \n",
    "    -\n",
    "    \n",
    "        name: APPLN_ABSTRACT\n",
    "        \n",
    "        type: text\n",
    "        \n",
    "        missing_value_strategy: ''\n",
    "        \n",
    "    -\n",
    "    \n",
    "        name: PSN_NAME\n",
    "        \n",
    "        type: text\n",
    "        \n",
    "        missing_value_strategy: ''\n",
    "        \n",
    "\n",
    "output_features:\n",
    "\n",
    "    -\n",
    "    \n",
    "        name: IPC4\n",
    "        \n",
    "        type: category\n",
    "\n",
    "\n",
    "\n",
    "and start the training typing the following command in your console:\n",
    "\n",
    "#### ludwig train --data_csv patent_data.csv --model_definition_file model_definition.yaml --output_directory patresults1\n",
    "\n",
    "or run the batch file \n",
    "\n",
    "### ludwig_run_pat.bat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "(note you can distribute the training of your models using Horovod, which allows to train on a single machine with multiple GPUs as well as on multiple machines)\n",
    "\n",
    "## what happens:\n",
    "\n",
    "\n",
    "After training, Ludwig will create a directory under results containing the trained model with its hyperparameters and summary statistics of the training process. \n",
    "\n",
    "Inside the folders you will find a lot of intermediate files: in particular  one HDF5 and one JSON. The HDF5 file contains the data mapped to numpy ndarrays, while the JSON file contains the mappings from the values in the tensors to their original labels.\n",
    "When rerunning the training or going to next steps, those files will be used to save time.\n",
    "\n",
    "Data can be splitted among  train, validation and test in several ways: either providing a column named SPLIT or three separate data sets (--data_train_csv, --data_validation_csv, --data_test_csv).\n",
    "\n",
    "Other important files are:\n",
    "\n",
    "description.json - a file containing a description of the training process with all the information to reproduce it.\n",
    "\n",
    "training_statistics.json which contains records of all measures and losses for each epoch.\n",
    "\n",
    "model - a directory containing model hyperparameters, weights, checkpoints and logs (for TensorBoard).\n",
    "\n",
    "\n",
    "## visualize training results\n",
    "\n",
    "\n",
    "You can visualize them using one of the several visualization options available in the visualize tool,\n",
    "\n",
    "\n",
    "ludvig visualize -v (type of graph) -ts/ps path to stats.json\n",
    "\n",
    "#### ludwig visualize --visualization learning_curves --training_statistics path/to/training_statistics.json\n",
    "\n",
    "or run \n",
    "\n",
    "#### ludwig_vis_pat.bat\n",
    "\n",
    "\n",
    "\n",
    "other visualizations available:\n",
    "\n",
    "https://uber.github.io/ludwig/user_guide/#visualizations\n",
    "\n",
    "\n",
    "confusion_matrix\n",
    "\n",
    "compare_performance\n",
    "\n",
    "compare_classifiers_performance_from_pred\n",
    "\n",
    "### how to read loss and accuracy:\n",
    "\n",
    "The lower the loss, the better a model. The loss is calculated on training and validation and its interperation is how well the model is doing for these two sets. Unlike accuracy, loss is not a percentage. It is a summation of the errors made for each example in training or validation sets.\n",
    "\n",
    "Loss is often used in the training process to find the \"best\" parameter values for your model \n",
    "\n",
    "Accuracy is more from an applied perspective. Once you find the optimized parameters above, you use this metrics to evaluate how accurate your model's prediction is compared to the true data.\n",
    "\n",
    "\n",
    " Hits@K measure: counts a prediction as correct if the model produces it among the first k\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict\n",
    "\n",
    "If you want your previously trained model to predict target output values, you can type the following command in your console:\n",
    "\n",
    "#### ludwig predict --data_csv path/to/data.csv --model_path /path/to/model -od output directory\n",
    "\n",
    "Running this command will return model predictions and some test performance statistics if the new dataset contains ground truth information to compare to. Those can be visualized by the visualize tool, which can also be used to compare performances and predictions of different models, for instance:\n",
    "\n",
    "\n",
    "#### ludwig visualize --visualization compare_performance -ps path/to/test_statistics_model_1.json path/to/test_statistics_model_2.json\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://dev.to/chrishunt/code-free-machine-learning-with-ludwig-2gap\n",
    "    \n",
    "    https://towardsdatascience.com/metrics-to-evaluate-your-machine-learning-algorithm-f10ba6e38234"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note with\n",
    "\n",
    "### ludwig.experiment\n",
    "\n",
    "it is possible to run train & predict at once\n",
    "\n",
    "#### ludwig experiment  --data_csv cars.csv --model_definition_file modeldef.yaml --output_directory results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the folder there are two versions of batch programs that run (ludwig_run_pat.bat and ludwig_run_pat_ipc4v2.bat)\n",
    "Ludwig and visualize (ludwig_vis_pat.bat and ludwig_vis_pat_ipc4v2.bat) results\n",
    "\n",
    "the world document \n",
    "\n",
    "LUDWIG-quickgraphs.docx\n",
    "\n",
    "shows results\n",
    "\n",
    "note the two different models \n",
    "\n",
    "\n",
    "\n",
    "Improvements:\n",
    "\n",
    "at mode level:\n",
    "\n",
    "        level: word\n",
    "        encoder: parallel_cnn\n",
    "        preprocessing:\n",
    "          word_format: english_tokenize\n",
    "\n",
    "at training level:\n",
    "\n",
    "training:\n",
    "  batch_size: 128\n",
    "  epochs: 1000\n",
    "  early_stop: 50\n",
    "  learning_rate: 0.003\n",
    "  optimizer:\n",
    "    type: adagrad    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
