{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data modeling for ML \n",
    "\n",
    "This paragraph lists some handful tips to improve the data before applying any ML on the top of it.\n",
    "\n",
    "Is a set of general rules, to customize on your dataset.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute missing values in a reasonable setting.\n",
    "\n",
    "A common practice is to replace null values with 0.\n",
    "\n",
    "In case the column is a splitting node (f.i. RD expenses > 10M $) the value of zero\n",
    "would assign all the null value records to a group, even if the value is unknown in reality.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode categorical variables carefully.\n",
    "\n",
    "Categorical variables don't work well when there are too many distinct values in them.\n",
    "\n",
    "Solution could to replace them with average value in each category;\n",
    "\n",
    "Another solution is 'one hot encoding' that means to transform categories into binary variables \n",
    "('COMPANY', 'UNIVERSITY, 'INDIVIDUAL' becomes f.i new variable 'IS_COMPANY' 0/1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use common sense to correct part of the data.\n",
    "\n",
    "Haw a look at data and where they make no sense, correct with null values or remove them\n",
    "\n",
    "F.I EMPLOYEES_NO <0 ; fundation_year 2099 ; inventor_name = IBM ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data with different structures.\n",
    "\n",
    "There are cases where data that refer to very different type of entities are packe together.\n",
    "\n",
    "For instance a dataset with patents from individuals and companies together.\n",
    "\n",
    "Due to structural differences distribution of data is different as well;\n",
    "\n",
    "You split the dataset into two different datasets based on ‘applicant_type’, you’ll find the model accuracy is improved.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deal with highly correlated variables.\n",
    "\n",
    "[1] For better interpretability and less model training time (but sacrificing a bit model accuracy), you can select the one with the highest feature importance and discard the others.\n",
    "\n",
    "[2] When doing feature selections, these correlated variables together may be provide a lot of information, but because they’re similar, it could happen that each individual feature has low feature importance. So select features with care when this happens.\n",
    "\n",
    "[3] Logistic regression would be affected by multi-colinearity but not tree models. It won’t hurt much if you just leave all correlated features in your model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Don’t select feature simply based on correlation with labels.\n",
    "\n",
    "Some features could not correlate well with predict variable but add a lot of information when combined with other features.\n",
    "\n",
    "For instance number of pages in an article could not directly correlate to forward citations;\n",
    "\n",
    "Nevertheless joint with journal name algorithm could split between short notes and proper articles, \n",
    "where the latter kind is more likely to recevie a higher number of citations.\n",
    "\n",
    "Variables interactions can be very important.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make sure the rows you’re building model on are truely DISTINCT.\n",
    "\n",
    "Unless you are dealing with record linkages or entity disambiguation, ccheck if multiple records in the same dataset might refer to the same record."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect data issues from weird variable distributions\n",
    "\n",
    "Draw some graphs for the distribution of your main variables and see whether there could be some issue\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How much data is enough for modeling?\n",
    "\n",
    "This depends much on how data have been collected.\n",
    "\n",
    "If we assume that all records are collected independently, randomly drawn from the whole population with equal probability even a relatively small dataset could bring good results.\n",
    "\n",
    "But in reality, the above assumptions won’t hold, the samples won’t be i.i.d (indepedent and identically distributed), the calculation of confidence intervals won’t be very precise, we will also have a lot of other features in our dataset, and the model predictions for each record won’t be i.i.d either.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
