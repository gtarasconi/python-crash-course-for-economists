{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas key features\n",
    "\n",
    "Fast and efficient DataFrame object with default and customized indexing.\n",
    "\n",
    "Tools for loading data into in-memory data objects from different file formats.\n",
    "\n",
    "Data alignment and integrated handling of missing data.\n",
    "\n",
    "Reshaping and pivoting of date sets.\n",
    "\n",
    "Label-based slicing, indexing and subsetting of large data sets.\n",
    "\n",
    "Columns from a data structure can be deleted or inserted.\n",
    "\n",
    "Group by data for aggregation and transformations.\n",
    "\n",
    "High performance merging and joining of data.\n",
    "\n",
    "Time Series functionality.\n",
    "\n",
    "### INSTALL:\n",
    "\n",
    "python -m pip install pandas\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas & dataframes\n",
    "\n",
    "We will go through Pandas via examples, bases on WOS data\n",
    "\n",
    "Pandas allows to load data into objects named DATAFRAMES or SERIES\n",
    "\n",
    "Series: a pandas Series is a one dimensional data structure (“a one dimensional ndarray”) that can store values — and for every value it holds a unique index, too.\n",
    "\n",
    "DataFrame: a pandas DataFrame is a two (or more) dimensional data structure – basically a table with rows and columns. The columns have names and the rows have indexes.\n",
    "\n",
    "Also PANEL type object (container of dataframes) exists.\n",
    "\n",
    "First example creates a random df where index is a progressive number\n",
    "\n",
    "The second example uses a list of dates as index;\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame(np.random.randn(6, 4),  columns=list('ABCD'))\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.date_range('20190101', periods=6)\n",
    "\n",
    "df = pd.DataFrame(np.random.randn(6, 4), index=dates)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A DF can be also created by passing a dictionary of objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({'A': 1.,\n",
    "                    'B': pd.Timestamp('20130102'),\n",
    "                    'C': pd.Series(1, index=list(range(4)), dtype='float32'),\n",
    "                    'D': np.array([3] * 4, dtype='int32'),\n",
    "                    'E': pd.Categorical([\"test\", \"train\", \"test\", \"train\"]),\n",
    "                    'F': 'foo'})\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing DFs from files\n",
    "\n",
    "Pandas can read a Csv file with just one function: read_csv().\n",
    "\n",
    "quick functions to visualize df:\n",
    "\n",
    "head() function to print the first five rows.\n",
    "data.head()\n",
    "\n",
    "data.tail(3) last 3 rows\n",
    "data.index shows values and dtype of index\n",
    "data.columns shows a series object with all column names\n",
    "\n",
    "an advanced tool is QGRID\n",
    "qgrid is a widget that allows advanced view of dataframes\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import qgrid\n",
    "\n",
    "data = pd.read_csv(\"wos_publications.csv\")\n",
    "# data.head()\n",
    "qgrid_widget = qgrid.show_grid(data,show_toolbar=True)\n",
    "qgrid_widget\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# qgrid_widget.get_changed_df()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is make some basic statistics to understand how dataframes get data\n",
    "\n",
    " dataframe.field_name\n",
    " \n",
    " dataframe['field_name']\n",
    " \n",
    " dataframe[['field1', ... 'fieldn']]  (argument here is a list [l1,l2..ln]\n",
    "\n",
    "adding a range [start:end] selects a subset (leading and traling record are excluded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.abstract[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['UID', 'pubyear']][3:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### isna() dropna()\n",
    "\n",
    "Another useful feature .isna() allows to display fields which have null values\n",
    "\n",
    "if we also add .sum() we can have a quick statistic showing which fields have null value \n",
    "and how many records for each field;\n",
    "\n",
    "in case we'd need only data where all fields contain value we could apply \n",
    "\n",
    "dataset = dataset.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data selection: \n",
    "\n",
    "loc, iloc, boolean indexing and isin\n",
    "\n",
    "are function that allow to access data\n",
    "\n",
    "loc: Access a group of rows and columns by label(s)\n",
    "iloc: Purely integer-location based indexing for selection by position.\n",
    "df[df.column + condition] --> retuns only records where condition is true\n",
    "df[df.column.isin(['val1,'val2'...'valn'])] returns records where column values are in the list \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[1:5, ['pubyear', 'doc_type']] # records 1 to 5 year and type of publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[1:6, [8, 5]] # same as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.pubyear<1999][:3]  # first 3 articles with year < 1999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we want to search some text...\n",
    "\n",
    "data[data.source.str.contains('STUDIES')].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['pubyear'].isin([1999])][:3]  # 3 records of 1999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or selecting articles titles in journals of management, dropping duplicates with function\n",
    "\n",
    "drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "journals = ['MANAGEMENT SCIENCE', 'STRATEGIC MANAGEMENT JOURNAL']\n",
    "mgt = data[data['source'].isin(journals)]\n",
    "mgt['itemtitle'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some basic statistic functions:\n",
    "\n",
    "As in many other languages you can use max() min() mean() median() count() sum()\n",
    "like: dataframe.column.function()  (ie : data.pubyear.min() )\n",
    "\n",
    "describe() shows a quick statistic summary of your data\n",
    "\n",
    "groupby(column) creates an object with stats for group;\n",
    "count() function allows to show the total of non null ('NaN') fields\n",
    "\n",
    "Other useful methods are \n",
    "\n",
    "rank() Data Ranking produces ranking for each element in the array of elements.\n",
    "\n",
    "corr() Correlation shows the linear relationship between any two array of value.\n",
    "\n",
    "cov() The Series object has a method cov to compute covariance between series objects.\n",
    "\n",
    "pct_change() This function compares every element with its prior element and computes the change percentage.\n",
    "\n",
    "rolling(window = n).funct() : applies to a rolling window a given function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('pubyear').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is to select count only for one fields\n",
    "to make things easier we create a new DF with group by data\n",
    "and we show content for UID field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = data.groupby('pubyear')\n",
    "print (grouped['UID'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['pubyear'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drawing\n",
    "\n",
    "By using matplotlib now we draw the trend of number of articles by year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%pylab inline\n",
    "grouped['UID'].count().plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort and transpose\n",
    "\n",
    "DF can be sorted by index or by values\n",
    "\n",
    ".T allows also transposing\n",
    "\n",
    "df.sort_index(axis=1, ascending=False, inplace=True)   [default makes a copy]\n",
    "sorts objects by labels along the given axis\n",
    "axis : index (0), or  columns names (1) to direct sorting\n",
    "\n",
    "\n",
    "df.sort_values(by='column name', ascending=False)\n",
    "sorts all dataset by columns values\n",
    "\n",
    "Note: when sorting by values the inndex could be no more ordered, you can apply method .reset_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=pd.DataFrame(grouped['UID'].count())\n",
    "a.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.sort_values(by='UID', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating Dataframes\n",
    "\n",
    "Now we want to do some update to the existing dataset\n",
    "\n",
    "we start by adding a new column PTYPE that contains only one letter instead of the full description of kind of publication\n",
    "that is contained in column pubtype\n",
    "\n",
    "then we want to set values as follows:\n",
    "\n",
    "Journal  = A\n",
    "Book in series = B\n",
    "\n",
    "We might do a 'case by case' update using a where condition like\n",
    "data.loc[df['pubtype'] == 'Journal', 'ptype'] = 'A'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ptype']=data['pubtype']\n",
    "\n",
    "# this case works but should be avoided: use dict instead\n",
    "# data.loc[df['pubtype'] == 'Journal', 'ptype'] = 'A'\n",
    "# data.loc[df['pubtype'] == 'Book in series', 'ptype'] = 'B'\n",
    "\n",
    "d1 = { 'Journal': \"A\",\n",
    "       'Book in series': 'B'}\n",
    "\n",
    "data.replace({'ptype': d1}, inplace=True)  #inplace makes it store; try without\n",
    "\n",
    "data.head(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Similar results could be obtained with \n",
    "\n",
    "np.where() \n",
    "\n",
    "\n",
    "function, fos instance to set atype = A if journal, else Other \n",
    "\n",
    "\n",
    "data['atype'] = np.where(newdata['ptype']=='A', 'Article', 'Other')\n",
    "\n",
    "Now we use groupby to check how many A and B type publications are in our data\n",
    "Eventually we also use the function unique() on doc_type to see what subkind of \n",
    "publications;\n",
    "in the last line we extract a count of the copy ptype, doc_type to check also \n",
    "doc_type correspondance to publication macro type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('ptype')['UID'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['doc_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(['ptype','doc_type'])['UID'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the examples above just show the result of operation without storing it\n",
    "neither in the existing DF nor in a new one.\n",
    "\n",
    "We might eventually think of creating a dataset with the count by ptype:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "newdata = data.groupby('ptype')['UID'].count()\n",
    "newdata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You see the new dataframe has ptype as index so we should add \n",
    "\n",
    "reset_index() \n",
    "\n",
    "function if we want the index column\n",
    "\n",
    "if you run then newdata.index before and after you will see the descrption of the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdata = data.groupby('ptype')['UID'].count().reset_index()\n",
    "newdata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eventually we could also decide to add a column with the count to the main dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['count'] = data.groupby('ptype')['UID'].transform('count')\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterating dataframes\n",
    "\n",
    "iteritems() − to iterate over the (key,value) pairs\n",
    "is a sort of horizontal scan by field name\n",
    "\n",
    "iterrows() − iterate over the rows as (index,series) pairs\n",
    "sans each row by index \n",
    "\n",
    "itertuples() − iterate over the rows as namedtuples\n",
    "returns an object where we have all values and names plus index value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1= data.iloc[0:2, 0:5]\n",
    "for key,value in df1.iteritems():\n",
    "   print (key)\n",
    "   print (value)\n",
    "   print ('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row_index,row in df1.iterrows():\n",
    "   print (row_index)\n",
    "   print (row)\n",
    "   print ('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in df1.itertuples():\n",
    "    print (row.UID)\n",
    "    print (row)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions apply()\n",
    "\n",
    "apply takes a function and applies it to all values of pandas series.\n",
    "\n",
    "\n",
    "dataframe.apply(func, convert_dtype=True, args=())\n",
    "\n",
    "func: .apply takes a function and applies it to all values of pandas series.\n",
    "\n",
    "convert_dtype: Convert dtype as per the function’s operation.\n",
    "\n",
    "args=(): Additional arguments to pass to function instead of series.\n",
    "\n",
    "Return Type: Pandas Series after applied function/operation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_p(text):\n",
    "    \n",
    "    try: \n",
    "        return text.replace('<p>', '')\n",
    "    except AttributeError:\n",
    "        return np.NaN\n",
    "\n",
    "\n",
    "data['abstract']=data['abstract'].apply(remove_p)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
