{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Pandas\n",
    "Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FIND first article by journal:\n",
    "\n",
    "Using WOS dataset, find for each journal name the first article title in chronological order;\n",
    "in case I have more than one article for the same year, the first in alfabetic order should be taken\n",
    "Columns involved are source (journal name) pubyear itemtitle\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(\"wos_publications.csv\")\n",
    "\n",
    "data.head(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, first we sort data by journal, year, article title to be sure all is ok\n",
    "Then we extract the first record after grouping by source\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data2 = data.sort_values(by=['source','pubyear','itemtitle']).reset_index()\n",
    "\n",
    "data2.groupby(['source'])['itemtitle','pubyear'].first().head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to check on one journal whether what we extracted was correct\n",
    "data[data['source']=='ACADEMY OF MANAGEMENT ANNALS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 keywords search\n",
    "\n",
    "Create a short list of keywords (3,4) then show articles that have in title AND abstract at least one keyword.\n",
    "\n",
    "Fields involved: itemtile, abstract.\n",
    "\n",
    "First step: list creation.\n",
    "\n",
    "Then we concatenate the keywords with a or \"|\" operator that \n",
    "will work in str.contains  (the function is based on regexp rules we will see in detail later on)\n",
    "\n",
    "Eventually we also need to uppercase the content of title and abstract when searching\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['MARKET','ORGANIZATION', 'STRATEGY' ]\n",
    "\n",
    "\n",
    "a = ''\n",
    "for k in keywords:\n",
    "    a = a + k + '|'\n",
    "\n",
    "a1 = a[:-1]    # removes last appended |\n",
    "\n",
    "\n",
    "data2= data[(data.abstract.str.upper().str.contains(a1)==True) & (data.itemtitle.str.upper().str.contains(a1)==True)]\n",
    "\n",
    "data2.count()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop on keywords using concat to get where the SAME kword occurs in title & abstract\n",
    "# \n",
    "\n",
    "data3 = pd.concat([data[(data['abstract'].str.upper().str.contains(k)==True) \n",
    "                        & (data['itemtitle'].str.upper().str.contains(k)==True)] for k in keywords], \n",
    "                        ignore_index=True)\n",
    "\n",
    "data3.drop_duplicates()  #needed to get rid of articles 'multikeyword'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b finding those who have ALL the keywords in the list\n",
    "\n",
    "This is a little more complicate, esp√®ecially if we want to keep it general for any possible list\n",
    "\n",
    "We will make a copy of our DF and delete one by one \n",
    "the line who do not fulfill the 2 conditions\n",
    "\n",
    "I changed the list since otherwise we always have an empty result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "keywords = ['MAR','ORG', 'STR' ]\n",
    "\n",
    "data3= data.copy()\n",
    "\n",
    "for k in keywords:\n",
    "    data3.drop(data3[(data3.abstract.str.upper().str.contains(k)!=True) \n",
    "                     | (data3.itemtitle.str.upper().str.contains(k)!=True)].index, inplace=True)\n",
    "\n",
    "data3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistics on DF from point 2\n",
    "\n",
    "Create a new dataframe with the data selected at point 2 and make a count by year and a count by journal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.groupby('pubyear')['UID'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.groupby('source')['UID'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
