{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regular expressions\n",
    "\n",
    "Regexes let us work with patterns.\n",
    "\n",
    "Is helpful to:\n",
    "\n",
    "Standardize / clean batches of data (replace)\n",
    "Extract pieces of information (parsing)\n",
    "\n",
    "module name: re\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in order to test regexp you can also try \n",
    "\n",
    "https://regex101.com/\n",
    "\n",
    "where you can insert the regular expression and a test string.\n",
    "\n",
    "BASICS\n",
    "\n",
    "- . any char\n",
    "- ^ leading\n",
    "- $ trailing\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "GROUPS and SPECIAL CHARS\n",
    "- \\b to match a word boundary\n",
    "- \\n or \\r\\n newline\n",
    "- \\s whitespaces   (vs \\S : no spaces)\n",
    "- \\d digits [0-9]  (vs \\D : no digits)\n",
    "- \\w matches chars [0-9A-Za-z_]\n",
    "\n",
    "\n",
    "\n",
    "REPETITIONS:\n",
    "\n",
    "- () contains agroup of chars to apply following:\n",
    "- match one or more chars:  +\n",
    "- match 0 or more chars:    * \n",
    "- match 0 or 1 repetitions: ?  (avoids greedy)\n",
    "- a{4} matches exactly 4 repetitions\n",
    "- 0{3,7} matches at least 3 but no more than 7 repetitions\n",
    "- | = or\n",
    "\n",
    "example (ab|cd)+\n",
    "\n",
    "SETS\n",
    "\n",
    "- [abc]: a b or c\n",
    "- [a-z]: any letter a to z (ascii order) \n",
    "- [^abc] : negative set: where not in abc\n",
    "\n",
    "example: [0-9] = \\d\n",
    "\n",
    "\n",
    "SYMBOLIC ACCESS\n",
    "- (?P<name>...) the substring matched by the group is accessible via the symbolic group name name\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find\n",
    "\n",
    "To Find an expression within a text exits the operator .search(text)\n",
    "\n",
    "We need before to compile() the pattern, then apply serch to the compiled pattern.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APPLE CORP\n"
     ]
    }
   ],
   "source": [
    "patterns= ['IBM', 'APPLE', 'INTEL']\n",
    "    \n",
    "lines = ['GOOGLE CORP', 'AMAZON LTD', 'APPLE CORP']    \n",
    "    \n",
    "for line in lines:    \n",
    "    for pattern in patterns:\n",
    "        rx = re.compile(pattern)    #  these 3 lines might be  \n",
    "        match = rx.search(line)     #  compressed in one:\n",
    "        if match:                   #  if re.compile(pattern).search(line):\n",
    "            print(line)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regex parsing\n",
    "\n",
    "Regex is very powerful when used together with dictionaries\n",
    "(hardcoded or even better loaded from file / external dbs)\n",
    "\n",
    "Along with symbolic patterns (?P<variable_name>regexp_pattern) allows data parsing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City HELSINKI\n",
      "Country FINLAND\n",
      "Zip 00014\n"
     ]
    }
   ],
   "source": [
    "rx_dict = {'City':     re.compile(r' (?P<City>(\\w+)), \\w+$'),\n",
    "           'Country':  re.compile(r', (?P<Country>(\\w+))$'),\n",
    "           'Zip':      re.compile(r'(?P<Zip>(\\d{3,5}))') }\n",
    "\n",
    "line= \"00014 UNIV HELSINKI, DEPT FOREST ECOL, HELSINKI, FINLAND\"\n",
    "\n",
    "for key, rx in rx_dict.items():\n",
    "    match = rx.search(line)\n",
    "    if match:\n",
    "        print(key, match.group(key)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use a list of addresses for WOS \n",
    "\n",
    "(file 06_wos_addresses_for_regexp.csv ) in a dataframe to parse it and add fields in \n",
    "\n",
    "dataframe itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address_id_se</th>\n",
       "      <th>full_address</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>&amp; INST DETUDES AVANCEES NANTES, CTR CAVAILLSS,...</td>\n",
       "      <td>FRANCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>&amp; UNIV, CHINESE ACAD SCI, CHINESE ACAD SCI, IN...</td>\n",
       "      <td>PEOPLES R CHINA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>'ATHOLIC UNIV DAEGU, DEPT OCCUPAT HLTH, GYONGS...</td>\n",
       "      <td>SOUTH KOREA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>'HUNGNAM NATL UNIV HOSP, DAEJEON, SOUTH KOREA</td>\n",
       "      <td>SOUTH KOREA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>'ONGGUK UNIV, GYEONGJU HOSP, GYEONGJU, SOUTH K...</td>\n",
       "      <td>SOUTH KOREA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   address_id_se                                       full_address  \\\n",
       "0              1  & INST DETUDES AVANCEES NANTES, CTR CAVAILLSS,...   \n",
       "1              4  & UNIV, CHINESE ACAD SCI, CHINESE ACAD SCI, IN...   \n",
       "2              6  'ATHOLIC UNIV DAEGU, DEPT OCCUPAT HLTH, GYONGS...   \n",
       "3              7      'HUNGNAM NATL UNIV HOSP, DAEJEON, SOUTH KOREA   \n",
       "4              8  'ONGGUK UNIV, GYEONGJU HOSP, GYEONGJU, SOUTH K...   \n",
       "\n",
       "           country  \n",
       "0           FRANCE  \n",
       "1  PEOPLES R CHINA  \n",
       "2      SOUTH KOREA  \n",
       "3      SOUTH KOREA  \n",
       "4      SOUTH KOREA  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "infile = '06_wos_addresses_for_regexp.csv'\n",
    "\n",
    "wos_addr_df = pd.read_csv(infile)\n",
    "\n",
    "wos_addr_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address_id_se</th>\n",
       "      <th>full_address</th>\n",
       "      <th>country</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Zip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>&amp; INST DETUDES AVANCEES NANTES, CTR CAVAILLSS,...</td>\n",
       "      <td>FRANCE</td>\n",
       "      <td>NANTES</td>\n",
       "      <td>FRANCE</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>&amp; UNIV, CHINESE ACAD SCI, CHINESE ACAD SCI, IN...</td>\n",
       "      <td>PEOPLES R CHINA</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>'ATHOLIC UNIV DAEGU, DEPT OCCUPAT HLTH, GYONGS...</td>\n",
       "      <td>SOUTH KOREA</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>71270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>'HUNGNAM NATL UNIV HOSP, DAEJEON, SOUTH KOREA</td>\n",
       "      <td>SOUTH KOREA</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>'ONGGUK UNIV, GYEONGJU HOSP, GYEONGJU, SOUTH K...</td>\n",
       "      <td>SOUTH KOREA</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9</td>\n",
       "      <td>'OREA ELECT TECHNOL INST, DEPT MULTIMEDIA, IP ...</td>\n",
       "      <td>SOUTH KOREA</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>46340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11</td>\n",
       "      <td>'YEONGSANG NATL UNIV, DIV APPL LIFE SCI PLUS B...</td>\n",
       "      <td>SOUTH KOREA</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>66070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13</td>\n",
       "      <td>()SITAR UNIV, COLL ENGN, GAS PROC CTR, POB 271...</td>\n",
       "      <td>QATAR</td>\n",
       "      <td>DOHA</td>\n",
       "      <td>QATAR</td>\n",
       "      <td>2713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15</td>\n",
       "      <td>(EMBRAPA CERRADOS, BR 020,KM 18,CAIXA POSTAL 0...</td>\n",
       "      <td>BRAZIL</td>\n",
       "      <td>DF</td>\n",
       "      <td>BRAZIL</td>\n",
       "      <td>020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16</td>\n",
       "      <td>(R)EVOLUT GMBH, D-53113 BONN, GERMANY</td>\n",
       "      <td>GERMANY</td>\n",
       "      <td>BONN</td>\n",
       "      <td>GERMANY</td>\n",
       "      <td>53113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>17</td>\n",
       "      <td>*, *, WASHINGTON, DC 20420 USA</td>\n",
       "      <td>USA</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>20420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>18</td>\n",
       "      <td>,JOSIP JURAJ STROSSMAYER UNIV, OSIJEK MED FAC,...</td>\n",
       "      <td>CROATIA</td>\n",
       "      <td>31000</td>\n",
       "      <td>CROATIA</td>\n",
       "      <td>31000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>19</td>\n",
       "      <td>,UNIVERS NAMUR, NTHC, NAMUR RES INST LIFE SCI ...</td>\n",
       "      <td>BELGIUM</td>\n",
       "      <td>YVOIR</td>\n",
       "      <td>BELGIUM</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>22</td>\n",
       "      <td>/HOSP SANTA MARTA, CTR HOSP LISBOA CENT, SERV ...</td>\n",
       "      <td>PORTUGAL</td>\n",
       "      <td>LISBON</td>\n",
       "      <td>PORTUGAL</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>25</td>\n",
       "      <td>0 18 KLIN, PEDIAT ENDOCRINOL, ISTANBUL, TURKEY</td>\n",
       "      <td>TURKEY</td>\n",
       "      <td>ISTANBUL</td>\n",
       "      <td>TURKEY</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    address_id_se                                       full_address  \\\n",
       "0               1  & INST DETUDES AVANCEES NANTES, CTR CAVAILLSS,...   \n",
       "1               4  & UNIV, CHINESE ACAD SCI, CHINESE ACAD SCI, IN...   \n",
       "2               6  'ATHOLIC UNIV DAEGU, DEPT OCCUPAT HLTH, GYONGS...   \n",
       "3               7      'HUNGNAM NATL UNIV HOSP, DAEJEON, SOUTH KOREA   \n",
       "4               8  'ONGGUK UNIV, GYEONGJU HOSP, GYEONGJU, SOUTH K...   \n",
       "5               9  'OREA ELECT TECHNOL INST, DEPT MULTIMEDIA, IP ...   \n",
       "6              11  'YEONGSANG NATL UNIV, DIV APPL LIFE SCI PLUS B...   \n",
       "7              13  ()SITAR UNIV, COLL ENGN, GAS PROC CTR, POB 271...   \n",
       "8              15  (EMBRAPA CERRADOS, BR 020,KM 18,CAIXA POSTAL 0...   \n",
       "9              16              (R)EVOLUT GMBH, D-53113 BONN, GERMANY   \n",
       "10             17                     *, *, WASHINGTON, DC 20420 USA   \n",
       "11             18  ,JOSIP JURAJ STROSSMAYER UNIV, OSIJEK MED FAC,...   \n",
       "12             19  ,UNIVERS NAMUR, NTHC, NAMUR RES INST LIFE SCI ...   \n",
       "13             22  /HOSP SANTA MARTA, CTR HOSP LISBOA CENT, SERV ...   \n",
       "14             25     0 18 KLIN, PEDIAT ENDOCRINOL, ISTANBUL, TURKEY   \n",
       "\n",
       "            country      City   Country    Zip  \n",
       "0            FRANCE    NANTES    FRANCE         \n",
       "1   PEOPLES R CHINA                             \n",
       "2       SOUTH KOREA                      71270  \n",
       "3       SOUTH KOREA                             \n",
       "4       SOUTH KOREA                             \n",
       "5       SOUTH KOREA                      46340  \n",
       "6       SOUTH KOREA                      66070  \n",
       "7             QATAR      DOHA     QATAR   2713  \n",
       "8            BRAZIL        DF    BRAZIL    020  \n",
       "9           GERMANY      BONN   GERMANY  53113  \n",
       "10              USA                      20420  \n",
       "11          CROATIA     31000   CROATIA  31000  \n",
       "12          BELGIUM     YVOIR   BELGIUM         \n",
       "13         PORTUGAL    LISBON  PORTUGAL         \n",
       "14           TURKEY  ISTANBUL    TURKEY         "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "for key, rx in rx_dict.items():\n",
    "\n",
    "    wos_addr_df[key] = wos_addr_df['full_address'].apply(lambda x: \n",
    "                                                         '' if not rx.search(x)\n",
    "                                                         else rx.search(x).group(key)\n",
    "                                                        )\n",
    "\n",
    "wos_addr_df.head(15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Anyway some patterns are more difficult than other.\n",
    "can anybody guess what type of address data can spot this patter?\n",
    "\n",
    "(?:[A-Za-z]\\d ?\\d[A-Za-z]{2})|(?:[A-Za-z][A-Za-z\\d]\\d ?\\d[A-Za-z]{2})|(?:[A-Za-z]{2}\\d{2} ?\\d[A-Za-z]{2})|(?:[A-Za-z]\\d[A-Za-z] ?\\d[A-Za-z]{2})|(?:[A-Za-z]{2}\\d[A-Za-z] ?\\d[A-Za-z]{2})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace\n",
    "\n",
    "re.sub(pattern, replace, string, count=0, flags=0)\n",
    "\n",
    "Allows multiple find and replace if pattern has multiple values held between parenthesis\n",
    "and replace has \\1 .. N for the arguments + other text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find duplicate lines in a text:\n",
    "\n",
    "PATTERN : ^(.*)(\\r?\\n\\1)+$ \n",
    "REPLACE : \\1\n",
    "    \n",
    "The caret will match only at the start of a line. \n",
    "So the regex engine will only attempt to match the remainder of the regex there. \n",
    "The dot and star combination simply matches an entire line, whatever its contents, if any. \n",
    "The parentheses store the matched line into the first backreference.\n",
    "\n",
    "Next we will match the line separator. \n",
    "Put the question mark into \\r?\\n to make this regex work with both Windows (\\r\\n) and UNIX (\\n) text files. \n",
    "So up to this point we matched a line and the following line break.\n",
    "\n",
    "Now we need to check if this combination is followed by a duplicate of that same line. \n",
    "We do this simply with \\1. This is the first backreference which holds the line we matched. \n",
    "The backreference will match that very same text.    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Johnny B. Goode'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# moves from surname, name 2nd name  to name 2nd name surname\n",
    "\n",
    "name = \"Goode, Johnny B.\"\n",
    "\n",
    "pattern= re.compile(r'([\\w-]+), ([\\w-]+) ([A-Z]\\.)')\n",
    "replace = r'\\2 \\3 \\1'\n",
    "           \n",
    "re.sub(pattern, replace, name, count=0, flags=0)           \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'24/12/2012, $50.00'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from MMDDYYYY to DDMMYYYY\n",
    "\n",
    "name = \"12/24/2012, $50.00\"\n",
    "\n",
    "pattern= re.compile(r'(\\d+)/(\\d+)/(\\d+)')\n",
    "replace = r'\\2/\\1/\\3'\n",
    "           \n",
    "re.sub(pattern, replace, name, count=0, flags=0)       \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove\n",
    "\n",
    "\n",
    "(?:...) A non-capturing version of regular parentheses. Matches whatever regular expression is inside the parentheses, but the substring matched by the group cannot be retrieved after performing a match; helpful to save memory / number of groups\n",
    "\n",
    "Example, remove optional part of zip code in US addresses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'New York, 10020, United States'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "name = \"New York 10020-9020 United States\"\n",
    "\n",
    "pattern= re.compile(r'( \\d{5})(?:-\\d{4})')\n",
    "replace = r',\\1,'\n",
    "           \n",
    "re.sub(pattern, replace, name, count=0, flags=0)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greediness and laziness\n",
    "\n",
    "Greedy quantifiers would match the longer text possible.\n",
    "\n",
    "Example: remove html tags\n",
    "(don't do it with regexp: better beautifulsoup module)\n",
    "\n",
    "Attempt to use <.+> would take anything between the first < and the last > in the text.\n",
    "\n",
    "\n",
    "Lazy quantifiers are sometimes also called \"ungreedy\" or \"reluctant\". You can do that by putting a question mark after the plus in the regex. You can do the same with the star, the curly braces and the question mark itself. So our example becomes <.+?>.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Today, I built a website which is now listed on various search engines.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "name = 'Today, I built a <a href=\"http://example.com\" style=\"color:green;\">website</a> which is now listed <a class=\"header remoteLink\" href=\"http://www.google.com\">on various search engines</a>.'\n",
    "\n",
    "pattern= re.compile(r'(<.*?>)')\n",
    "replace = r''\n",
    "           \n",
    "re.sub(pattern, replace, name, count=0, flags=0)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
